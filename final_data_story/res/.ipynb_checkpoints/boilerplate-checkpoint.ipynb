{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boilerplate Code for Final Blog\n",
    "*Similar to the the `functions.ipynb` file, this notebook is meant to consolidate the long blocks of code to be ran in the background so that they do not obscure what is presented in the blog text.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import sample\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute function definitions for later use\n",
    "%run ../data_analysis/functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PROCESSING STEPS\n",
    "\n",
    "# Read in Tweet data and create two lists of dictionairies\n",
    "pre_covid_tweets = []\n",
    "post_covid_tweets = []\n",
    "summary = []\n",
    "\n",
    "# Handle pre-covid data\n",
    "for filename in os.listdir('../../data/pre_covid'):\n",
    "    try:\n",
    "        json_string = open(f'../../data/pre_covid/{filename}').read()\n",
    "        tweets = json.loads(json_string)\n",
    "        summary.append(('pre', len(tweets), filename.split('_')[0]))\n",
    "        pre_covid_tweets.extend(tweets)\n",
    "    except:\n",
    "        print(f'Error reading {filename}')\n",
    "        continue   \n",
    "        \n",
    "# Handle post-covid data\n",
    "for filename in os.listdir('../../data/post_covid'):\n",
    "    try:\n",
    "        json_string = open(f'../../data/post_covid/{filename}').read()\n",
    "        tweets = json.loads(json_string)\n",
    "        summary.append(('post', len(tweets), filename.split('_')[0]))\n",
    "        post_covid_tweets.extend(tweets)\n",
    "    except:\n",
    "        print(f'Error reading {filename}')\n",
    "        continue \n",
    "        \n",
    "# Remove some tweets to maintain consistent sample sizes\n",
    "try:\n",
    "    pre_covid_tweets = sample(pre_covid_tweets, len(post_covid_tweets))\n",
    "except:\n",
    "    post_covid_tweets = sample(post_covid_tweets, len(pre_covid_tweets))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT NORMALIZATION STEPS\n",
    "\n",
    "tt = TweetTokenizer()\n",
    "\n",
    "# Tokenize the Tweets to generate frequency lists\n",
    "pre_toks = []\n",
    "post_toks = []\n",
    "\n",
    "# Handle pre-covid tweets\n",
    "for tweet in pre_covid_tweets:\n",
    "    t = tweet['text']\n",
    "    pre_toks.extend(tt.tokenize(t))\n",
    "    \n",
    "# Handle post-covid tweets\n",
    "for tweet in post_covid_tweets:\n",
    "    t = tweet['text']\n",
    "    post_toks.extend(tt.tokenize(t))\n",
    "\n",
    "pre_dist = Counter(pre_toks)\n",
    "post_dist = Counter(post_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_keywords():\n",
    "    keyness_df = calculate_keyness(pre_dist, post_dist, print_table=False, top=-1, keyness_threshold=-100000)\n",
    "    plot_keyitems(keyness_df, 20,\n",
    "              corpusA='Pre-COVID Tweets', \n",
    "              corpusB='Post-COVID Tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_freq_dist():\n",
    "    \n",
    "    # Find users who are represented in both corpora\n",
    "    pre_users = list(set([t['username'] for t in pre_covid_tweets]))\n",
    "    post_users = list(set([t['username'] for t in post_covid_tweets]))\n",
    "    longitudinal_users = [u for u in pre_users if u in post_users]\n",
    "    \n",
    "    # Initialize tweet dataframes\n",
    "    pre_df = pd.DataFrame(pre_covid_tweets) \n",
    "    post_df = pd.DataFrame(post_covid_tweets)\n",
    "\n",
    "    # Remove tweets that weren't posted by longitudinal users\n",
    "    pre_df = pre_df[pre_df['username'].apply(lambda u: u in longitudinal_users)]\n",
    "    post_df = post_df[post_df['username'].apply(lambda u: u in longitudinal_users)]\n",
    "    \n",
    "    # Plot histogram of pre-covid tweet frequency among longitudinal users\n",
    "    plt.hist(post_df.sample(20)['username'], alpha=0.5, edgecolor='blue', density=False)\n",
    "    plt.hist(pre_df.sample(20)['username'], alpha=0.5, edgecolor='red', density=False)\n",
    "    plt.title('Difference in Individual Antivax Tweet Frequency Before & After the COVID-19 Pandemic')\n",
    "    plt.legend(['Post-COVID', 'Pre-COVID'])\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.xlabel('Username')\n",
    "    plt.ylabel('Tweet Frequency Difference')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_users = list(set([t['username'] for t in pre_covid_tweets]))\n",
    "post_users = list(set([t['username'] for t in post_covid_tweets]))\n",
    "longitudinal_users = [u for u in pre_users if u in post_users]\n",
    "len(longitudinal_users)\n",
    "\n",
    "# Initialize tweet dataframes\n",
    "pre_df = pd.DataFrame(pre_covid_tweets) \n",
    "post_df = pd.DataFrame(post_covid_tweets)\n",
    "\n",
    "# Remove tweets that weren't posted by longitudinal users\n",
    "pre_df = pre_df[pre_df['username'].apply(lambda u: u in longitudinal_users)]\n",
    "post_df = post_df[post_df['username'].apply(lambda u: u in longitudinal_users)]\n",
    "\n",
    "pre_user_freq = Counter(pre_df['username'])\n",
    "post_user_freq = Counter(post_df['username'])\n",
    "\n",
    "pre_top = [f[0] for f in pre_user_freq.most_common(20)]\n",
    "post_top = [f[0] for f in post_user_freq.most_common(20)]\n",
    "top_posters = [u for u in pre_top if u in post_top]\n",
    "top_posters\n",
    "\n",
    "# Object for sentiment scoring\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "pre_df['polarity'] = pre_df['text'].map(lambda t: sid.polarity_scores(t)['compound'])\n",
    "post_df['polarity'] = post_df['text'].map(lambda t: sid.polarity_scores(t)['compound'])\n",
    "\n",
    "pre_top_df = pre_df[pre_df['username'].map(lambda u: u in top_posters)]\n",
    "post_top_df = post_df[post_df['username'].map(lambda u: u in top_posters)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both pre-covid and post-covid polarity scores side-by-side\n",
    "def top_poster_plot(user):\n",
    "    try:\n",
    "        color1 = 'red'\n",
    "        title1 = f'{user}\\'s Tweet Polarity Score Trends Before COVID-19'\n",
    "        x1 = pre_top_df[pre_top_df['username'] == user].sample(20)['created_at']\n",
    "        y1 = pre_top_df[pre_top_df['username'] == user].sample(20)['polarity']\n",
    "    except:\n",
    "        x1 = pre_top_df[pre_top_df['username'] == user]['created_at']\n",
    "        y1 = pre_top_df[pre_top_df['username'] == user]['polarity'] \n",
    "        \n",
    "    try:\n",
    "        color2 = 'blue'\n",
    "        title2 = f'{user}\\'s Tweet Polarity Score Trends After COVID-19'\n",
    "        x2 = post_top_df[post_top_df['username'] == user].sample(20)['created_at']\n",
    "        y2 = post_top_df[post_top_df['username'] == user].sample(20)['polarity']\n",
    "    except:\n",
    "        x2 = post_top_df[post_top_df['username'] == user]['created_at']\n",
    "        y2 = post_top_df[post_top_df['username'] == user]['polarity']        \n",
    "    \n",
    "    # Define figure size\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
    "    \n",
    "    # Pre-covid plot parameters\n",
    "    axes[0].plot(x1, y1, color=color1)\n",
    "    axes[0].set_xlabel('Date')\n",
    "    axes[0].set_ylabel('Polarity Score')\n",
    "    axes[0].set_xticklabels(x1, rotation=45)\n",
    "    axes[0].set_title(title1)\n",
    "    \n",
    "    # Post-covid plot parameters\n",
    "    axes[1].plot(x2, y2, color=color2)\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Polarity Score')\n",
    "    axes[1].set_xticklabels(x2, rotation=45)\n",
    "    axes[1].set_title(title2)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_plots():\n",
    "    for t in top_posters:\n",
    "        top_poster_plot(t)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
